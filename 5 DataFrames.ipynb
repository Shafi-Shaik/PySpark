{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abde8c43-42ac-4b4d-9040-ddc549d6cd7a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local[1]\") \\\n",
    "      .appName(\"practice 2\") \\\n",
    "      .getOrCreate() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d079e9cb-6463-49e1-acfe-55124906cc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ShafiVivobook.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>practice 2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x214040c2d70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c708addb-35f7-442a-b410-4eb419689d54",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1) Create Empty DataFrame with Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c355c3a-7024-4cda-8e3b-4b8c20496180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType\n",
    "\n",
    "schema1 = StructType([\n",
    "  StructField('firstname', StringType(), True),\n",
    "  StructField('middlename', StringType(), True),\n",
    "  StructField('lastname', StringType(), True)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d54802dc-e8f0-4ef2-a3d1-4e784b6d1fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create empty DataFrame directly.\n",
    "df2 = spark.createDataFrame([], schema1)\n",
    "df2.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ce779-d7f3-4769-87f2-ddd8d6e290b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2) Create empty DatFrame with no schema (no columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bf6f1f3-8731-4a9a-9107-3e0aab246b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df3 = spark.createDataFrame([], StructType([]))\n",
    "df3.printSchema()\n",
    "\n",
    "#print below empty schema\n",
    "#root\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0936de22-1e8c-4d04-bc71-c93e2ebbd487",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3) DataFrame from RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976338ad-3173-426b-b06c-7d2c984f0e84",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ddd0553-5c86-46d0-af7c-a7c5a1d42341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "a=[  (1,1.0,'shafi',date(2022,1,19)),\n",
    "     (3,4.0,'ravi',date(2022,12,31)),\n",
    "     (4,5.0,'karan',date(2022,11,1)),\n",
    "     (2,14.78,'nadeem',date(2022,11,4)),\n",
    "     (22,13.0,'mir',date(2022,7,9))\n",
    "  ]\n",
    "\n",
    "\n",
    "rdd2=spark.sparkContext.parallelize(a)\n",
    "type(rdd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fccc3a-f03a-4e96-bb88-7669466de6a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### a. using toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9404ec1-24ee-44fa-bc2a-74c436746ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sno: long (nullable = true)\n",
      " |-- GPA: double (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- DOJ: date (nullable = true)\n",
      "\n",
      "+---+-----+------+----------+\n",
      "|Sno|  GPA|  Name|       DOJ|\n",
      "+---+-----+------+----------+\n",
      "|  1|  1.0| shafi|2022-01-19|\n",
      "|  3|  4.0|  ravi|2022-12-31|\n",
      "|  4|  5.0| karan|2022-11-01|\n",
      "|  2|14.78|nadeem|2022-11-04|\n",
      "| 22| 13.0|   mir|2022-07-09|\n",
      "+---+-----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['Sno', 'GPA','Name','DOJ']\n",
    "\n",
    "df = rdd2.toDF(cols)\n",
    "\n",
    "df.printSchema()\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6fa544-5f01-4858-8290-084af141a985",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### b. using createDataFrame(rdd,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f552fecd-36d9-4648-8ec7-b1a44eb3df08",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+----------+\n",
      "|Sno|  GPA|  Name|       DOJ|\n",
      "+---+-----+------+----------+\n",
      "|  1|  1.0| shafi|2022-01-19|\n",
      "|  3|  4.0|  ravi|2022-12-31|\n",
      "|  4|  5.0| karan|2022-11-01|\n",
      "|  2|14.78|nadeem|2022-11-04|\n",
      "| 22| 13.0|   mir|2022-07-09|\n",
      "+---+-----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame(rdd2,schema=cols)\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa3e21c-033c-4690-893d-1aefc984a5e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### c. using createDataFrame along with StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "657b42c6-fe1f-4b9f-8d11-81ca18170022",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField,StructType, IntegerType, DateType\n",
    "\n",
    "deptSchema = StructType([       \n",
    "     StructField('S no', IntegerType(), True),\n",
    "     StructField('CGPA', StringType(), True),\n",
    "     StructField('Name', StringType(), True),\n",
    "     StructField('DOJ', DateType(), False)\n",
    "])\n",
    "df=spark.createDataFrame(rdd2,schema=deptSchema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc3ee83c-14da-4000-a447-e4ee9058dec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+----------+\n",
      "|S no| CGPA|  Name|       DOJ|\n",
      "+----+-----+------+----------+\n",
      "|   1|  1.0| shafi|2022-01-19|\n",
      "|   3|  4.0|  ravi|2022-12-31|\n",
      "|   4|  5.0| karan|2022-11-01|\n",
      "|   2|14.78|nadeem|2022-11-04|\n",
      "|  22| 13.0|   mir|2022-07-09|\n",
      "+----+-----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e35893-9dae-4c7b-976e-4dd8c624b326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- S no: integer (nullable = true)\n",
      " |-- CGPA: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- DOJ: date (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59cfd26-9031-4baf-8aaa-7ca5b7845028",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4) DataFrame with Adhoc Data (on the fly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d28d0622-40df-42bf-a503-baef9e9b73bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "  ('Michael','Rose','','2000-05-19','M',4000),\n",
    "  ('Robert','','Williams','1978-09-05','M',4000),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema = columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "005c34d9-f83a-44f4-8078-b3991ae90e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7ef922-9adf-4499-8f92-a071fba6f3a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5) DataFrame from external data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "132b558a-bfba-4db8-b9f5-fe8323f924a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"S:/Datasets/csv/titanic.csv\",header=True,inferSchema=True)\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2521e781-20f7-4ba5-8a6f-ec1419db3011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb13948-7be0-46dd-9dbb-e942d611e428",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
